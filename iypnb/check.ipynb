{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a7b9325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print('hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f32427a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Miniconda\\envs\\smc\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import Optional\n",
    "\n",
    "from fastapi import HTTPException\n",
    "from datetime import datetime\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88cf36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7, streaming= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69d3e58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def invoke_chain(prompt: PromptTemplate, inputs: dict) -> str:\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    res = await chain.ainvoke(inputs)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13c29c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def check_topic_relevance(user_question: str, topic_name: str) -> bool:\n",
    "    \"\"\"\n",
    "    Kiểm tra xem câu hỏi có liên quan đến chủ đề hay không.\n",
    "    Trả về True nếu liên quan, False nếu không liên quan.\n",
    "    \"\"\"\n",
    "    if not topic_name:\n",
    "        return True  \n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "Chủ đề của session: {topic_name}\n",
    "Câu hỏi của người dùng: {user_question}\n",
    "\n",
    "Hãy đánh giá xem câu hỏi của người dùng có liên quan đến chủ đề \"{topic_name}\" hay không.\n",
    "\n",
    "Trả lời CHỈ bằng một từ: \"CÓ\" nếu câu hỏi liên quan đến chủ đề, \"KHÔNG\" nếu không liên quan.\n",
    "Không giải thích thêm, chỉ trả lời \"CÓ\" hoặc \"KHÔNG\".\n",
    "\"\"\",\n",
    "        input_variables=[\"topic_name\", \"user_question\"],\n",
    "    )\n",
    "    \n",
    "    result = await invoke_chain(prompt, {\n",
    "        \"topic_name\": topic_name,\n",
    "        \"user_question\": user_question\n",
    "    })\n",
    "    \n",
    "    result_upper = result.strip().upper()\n",
    "    return \"CÓ\" in result_upper or \"YES\" in result_upper or \"TRUE\" in result_upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c1961bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relevance: False\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = await check_topic_relevance(\"Đề bài: Tính tổng 2 số\", \"asdfadsf\")\n",
    "print(f\"Relevance: {res}\")\n",
    "type(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ce889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def func_chatbot_qa_non_stream(question: str, answer: str, user_question: str, topic_name: Optional[str] = None) -> str:\n",
    "    \"\"\"Non-streaming version - returns complete result\"\"\"\n",
    "    if que:\n",
    "        is_relevant = await check_topic_relevance(user_question, question)\n",
    "        if not is_relevant:\n",
    "            return f\"Xin lỗi, câu hỏi của bạn không liên quan đến chủ đề **{topic_name}** của session này. Vui lòng hỏi các câu hỏi liên quan đến chủ đề này.\"\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "Đề bài: {question}\n",
    "Bài code của sinh viên: {answer}\n",
    "\n",
    "Câu hỏi của sinh viên: {user_question}\n",
    "{focus_topic}\n",
    "\n",
    "Bạn là trợ lý AI hỗ trợ sinh viên học lập trình. Hãy trả lời câu hỏi của sinh viên dựa trên ngữ cảnh đề bài và bài code của họ.\n",
    "\n",
    "QUY TẮC QUAN TRỌNG:\n",
    "- TUYỆT ĐỐI KHÔNG đưa ra đáp án hoàn chỉnh hoặc code mẫu giải bài tập\n",
    "- TUYỆT ĐỐI KHÔNG viết lại toàn bộ code đúng cho sinh viên\n",
    "- CHỈ hướng dẫn, gợi ý hướng đi, giải thích khái niệm, phân tích logic\n",
    "- Nếu sinh viên hỏi về lỗi cụ thể trong code của họ, CHỈ chỉ ra lỗi và gợi ý cách suy nghĩ để sửa, KHÔNG sửa code giúp họ\n",
    "- Nếu sinh viên hỏi về khái niệm (for, while, if, function, biến...), hãy giải thích rõ ràng với ví dụ đơn giản KHÔNG LIÊN QUAN đến bài tập của họ\n",
    "- Nếu sinh viên hỏi \"làm sao để...\", hãy hướng dẫn tư duy và các bước cần làm, KHÔNG viết code mẫu\n",
    "- Khuyến khích sinh viên tự suy nghĩ và thử nghiệm\n",
    "- Giới hạn ngữ cảnh trong phạm vi đề bài và code của sinh viên\n",
    "- Không cần chào \n",
    "Trả lời bằng tiếng Việt, xưng hô \"bạn\", giọng điệu thân thiện, động viên. Trả về kết quả dạng Markdown để dễ đọc.\n",
    "\"\"\",\n",
    "        input_variables=[\"question\", \"answer\", \"user_question\", \"focus_topic\"],\n",
    "    )\n",
    "    \n",
    "    focus_topic_text = f\"\\nLƯU Ý: Session này tập trung vào chủ đề **{topic_name}**. Hãy đảm bảo câu trả lời liên quan đến chủ đề này.\" if topic_name else \"\"\n",
    "    \n",
    "    return await invoke_chain(prompt, {\n",
    "        \"question\": question,\n",
    "        \"answer\": answer,\n",
    "        \"user_question\": user_question,\n",
    "        \"focus_topic\": focus_topic_text\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37b449ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss  = await func_chatbot_qa_non_stream(\"Đề bài: Tính tổng 2 số\", \"def sum(a, b): return a + b\", \"sdfsd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdaaacec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Có vẻ như bạn đang muốn tính tổng của hai số. Mình thấy bạn đã viết một hàm `sum` khá đơn giản và đúng về mặt logic. Tuy nhiên, nếu bạn muốn hiểu rõ hơn về cách hoạt động của hàm này hoặc cách sử dụng nó, mình có thể gợi ý một số điều bạn có thể làm:\\n\\n1. **Kiểm tra kiểu dữ liệu**: Bạn có thể kiểm tra xem hai tham số `a` và `b` có phải là số hay không trước khi thực hiện phép cộng. Điều này giúp đảm bảo rằng hàm của bạn hoạt động như mong đợi.\\n\\n2. **Gọi hàm**: Hãy thử gọi hàm `sum` với các giá trị khác nhau để xem kết quả. Bạn có thể thử với số dương, số âm, hoặc thậm chí là số thập phân.\\n\\n3. **Xử lý ngoại lệ**: Cân nhắc việc xử lý các trường hợp mà người dùng có thể nhập vào kiểu dữ liệu không hợp lệ (như chuỗi hoặc danh sách). Bạn có thể nghĩ đến việc sử dụng `try` và `except` để quản lý những lỗi này.\\n\\n4. **Giải thích tên hàm**: Bạn có thể xem xét việc đổi tên hàm `sum` thành một cái tên khác, vì `sum` là tên của một hàm có sẵn trong Python, điều này có thể gây nhầm lẫn.\\n\\nHãy thử nghiệm với những gợi ý này và xem điều gì xảy ra nhé! Nếu bạn có thêm câu hỏi hoặc cần sự hỗ trợ cụ thể hơn, cứ thoải mái hỏi. Chúc bạn thành công!'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
